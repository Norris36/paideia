{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d39806",
   "metadata": {},
   "source": [
    "# Introduction \n",
    " A second attempt at Spaced Repeititon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command \n",
    "# pip install --force-reinstall -r '..\\paideia\\requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.8.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "     ---------------------------------------- 0.0/65.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.6/65.6 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jbay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jbay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\jbay\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.14.6-cp312-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jbay\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.8.0-py3-none-any.whl (222 kB)\n",
      "   ---------------------------------------- 0.0/222.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 222.3/222.3 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB ? eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 4.1 MB/s eta 0:00:00\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.9 kB ? eta -:--:--\n",
      "   --------------------------------------  378.9/381.9 kB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 381.9/381.9 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.14.6-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/1.9 MB 18.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.2/1.9 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 14.9 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, h11, distro, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.8.0 pydantic-2.5.3 pydantic-core-2.14.6 sniffio-1.3.0 typing-extensions-4.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\jbay\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\jbay\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\jbay\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoup\n",
      "  Downloading BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\jbay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\jbay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\jbay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jbay\\AppData\\Local\\Temp\\pip-build-env-b3ra7umr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\jbay\\AppData\\Local\\Temp\\pip-build-env-b3ra7umr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\jbay\\AppData\\Local\\Temp\\pip-build-env-b3ra7umr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 480, in run_setup\n",
      "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\jbay\\AppData\\Local\\Temp\\pip-build-env-b3ra7umr\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 3\n",
      "          \"You're trying to run a very old release of Beautiful Soup under Python 3. This will not work.\"<>\"Please use Beautiful Soup 4, available through the pip package 'beautifulsoup4'.\"\n",
      "                                                                                                         ^^\n",
      "      SyntaxError: invalid syntax\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(60000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pyperclip as py\n",
    "# import PyPDF2\n",
    "import openai \n",
    "import regex as re\n",
    "import random \n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from requests.exceptions import MissingSchema\n",
    "import tiktoken # https://github.com/openai/tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_type  = os.getenv('OPENAI_TYPE')\n",
    "openai.api_base  = os.getenv('OPENAI_BASE')\n",
    "openai.api_version = os.getenv('OPENAI_VERSION')\n",
    "openai.api_key = os.getenv('OPENAI_KEY')\n",
    "\n",
    "%autosave 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(vec1,vec2):\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(vec1), np.array(vec2))\n",
    "\n",
    "def calculate_similarity(vector):\n",
    "    #print(type(vector),type(prompt_embedding))\n",
    "    similarity = vector_similarity(vector, prompt_embedding)\n",
    "    return similarity\n",
    "\n",
    "def embed_prompt_lookup(question: str) -> str:\n",
    "    # Your code remains unchanged until this line\n",
    "    prompt_embedding = get_embedding(question)\n",
    "\n",
    "    # Filter out rows with None values in the 'embedding' column\n",
    "    valid_new_df = new_df[new_df['embedding'].notna()]\n",
    "\n",
    "    # Get prompt similarity with embeddings\n",
    "    new_df['prompt_similarity'] = np.nan  # Initialize a new column with NaN values\n",
    "\n",
    "    for index, row in valid_new_df.iterrows():\n",
    "        vector = list(row['embedding'])\n",
    "        similarity = vector_similarity(vector, prompt_embedding)\n",
    "        new_df.at[index, 'prompt_similarity'] = similarity\n",
    "        \n",
    "    # Rest of the code remains unchanged\n",
    "    # get most similar summary\n",
    "    top_3_similar = df.nlargest(3, 'prompt_similarity')\n",
    "    summaries = top_3_similar['line'].tolist()\n",
    "\n",
    "    prompt = f\"\"\"Only answer the question below if you have 100% certainty of the facts, use the context below to answer.\n",
    "            The answer should be written as an email for a colleague in my organization.\n",
    "            The answer must include citing, in a footnotes format. Here's an example: '[n]'\n",
    "            Here is some context:\n",
    "            {summaries[0]}\n",
    "            {summaries[1]}\n",
    "            {summaries[2]}\n",
    "            Q: {question} \\n\\n\n",
    "            A:\"\"\"\n",
    "\n",
    "    # Use OpenAI to get the most similar answer\n",
    "    response = openai.Completion.create(\n",
    "        engine = 'text-davinci-003', # Use the text-davinci-003 engine\n",
    "        prompt=prompt, # Use the prompt created above\n",
    "        temperature=0, # Set the temperature to 0\n",
    "        max_tokens=500, # Set the maximum tokens to 500\n",
    "        model=\"text-davinci-003\" # Use the text-davinci-003 model\n",
    "    )\n",
    "    print(response[\"choices\"][0][\"text\"].strip(\" \\n\")) # Print the most similar answer```\n",
    "\n",
    "def get_embedding(text):\n",
    "    tries = 0\n",
    "    if isinstance(text, str):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    try:\n",
    "        result = openai.Embedding.create(\n",
    "            engine='text-embedding-ada-002',\n",
    "            model='text-embedding-ada-002',\n",
    "            input=text\n",
    "        )\n",
    "        return result[\"data\"][0][\"embedding\"]\n",
    "    except Exception as e:\n",
    "        #print(f\"Error: {e}\")\n",
    "        time.sleep(7)\n",
    "        if tries < 3:\n",
    "            get_embedding(text)\n",
    "            tries += 1\n",
    "            #print(tries)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def weird_func(string, encoding_name):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def read_pdf_to_string(file_path):\n",
    "    \"\"\"Reads a PDF file and returns the text as a string.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: The text from the PDF file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)  # Create a PDF reader object\n",
    "        num_pages = len(pdf_reader.pages)  # Get the number of pages in the PDF\n",
    "        text = \"\"\n",
    "\n",
    "        for page_number in range(num_pages):  # Iterate through each page\n",
    "            page = pdf_reader.pages[page_number]  # Get the page object\n",
    "            text += page.extract_text()  # Extract the text from the page\n",
    "\n",
    "    return text  # Return the text from the PDF\n",
    "\n",
    "def cleaner(text):\n",
    "    if isinstance(text, str):\n",
    "        list = []\n",
    "\n",
    "        text = text.replace('[', '')\n",
    "        text = text.replace(']', '')\n",
    "\n",
    "        for j in text.split(','):\n",
    "            j = j.strip()\n",
    "            list.append(float(j))\n",
    "        return list\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def my_reader(path):\n",
    "    embeddings = []\n",
    "    df = pd.read_csv(path)\n",
    "    for i in range(len(df)):\n",
    "        x = df.at[i, 'embedding']\n",
    "        y = cleaner(x)\n",
    "        embeddings.append(y)\n",
    "        \n",
    "    df['embedding'] = embeddings\n",
    "    return df\n",
    "\n",
    "def split_response(response, max_chars_per_line=500):\n",
    "    words = response.split(' ')\n",
    "    lines = []\n",
    "    current_line = words[0]\n",
    "\n",
    "    for word in words[1:]:\n",
    "        if len(current_line + \" \" + word) < max_chars_per_line:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line.strip())\n",
    "            current_line = word\n",
    "\n",
    "    lines.append(current_line.strip())\n",
    "    return lines\n",
    "\n",
    "def get_links_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extract all the links (a tags) from the page\n",
    "        links = soup.find_all(\"a\")\n",
    "        return links\n",
    "    except MissingSchema:\n",
    "        return []\n",
    "\n",
    "def process_links(links, visited_links):\n",
    "    new_links = []\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href:\n",
    "            if href.startswith('/hc/'):\n",
    "                href = 'https://support.steelseries.com' + href\n",
    "            if ('steelseries' in href) and (href not in visited_links):\n",
    "                visited_links.add(href)\n",
    "                new_links.append(href)\n",
    "    return new_links, visited_links\n",
    "\n",
    "def fetch_all_links(url):\n",
    "    visited_links = set()\n",
    "    to_visit = [url]\n",
    "\n",
    "    with tqdm(total=10000, desc=\"Links Processed\") as pbar:\n",
    "        while to_visit:\n",
    "            try:\n",
    "                if len(visited_links) > 10000:\n",
    "                    break\n",
    "\n",
    "                current_url = to_visit.pop()\n",
    "                links = get_links_from_url(current_url)\n",
    "                new_links, visited_links = process_links(links, visited_links)\n",
    "                to_visit.extend(new_links)\n",
    "                pbar.set_description(f\"Visited: {len(visited_links)}, To visit: {len(to_visit)}\")\n",
    "                pbar.update(1)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return visited_links\n",
    "    return visited_links\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    try:\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Remove script and style tags\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "\n",
    "        # Extract the text directly using .get_text() method\n",
    "        raw_text = soup.get_text(separator='\\n')\n",
    "\n",
    "        # Remove consecutive line breaks\n",
    "        lines = raw_text.split('\\n')\n",
    "        filtered_lines = [line for line in lines if line.strip() != '']\n",
    "        text = '\\n'.join(filtered_lines)\n",
    "        return text\n",
    "    except:\n",
    "        print('error')\n",
    "        return ''\n",
    "\n",
    "def get_redirect(url):\n",
    "    response = requests.head(url, allow_redirects=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        #print('The link is valid and returns a 200 status code.')\n",
    "        final_url = response.url\n",
    "        #print(f'The final URL is {final_url}.')\n",
    "    else:\n",
    "        #print('The link is invalid or does not return a 200 status code.')\n",
    "        final_url = url\n",
    "    return final_url\n",
    "\n",
    "def embed_prompt_lookup(question: str, key: str, df: pd.DataFrame) -> str:\n",
    "    #key = 'article'\n",
    "    prompt_embedding = get_embedding(question)\n",
    "\n",
    "    df['prompt_similarity'] = np.nan  \n",
    "\n",
    "    if len(key) > 3:\n",
    "        definition              = df[df.Name_ == sample_name].text.values[0]\n",
    "        definition_embedding    = df.loc[df.Name_ == sample_name, 'embedding'].values[0]\n",
    "        prompt_similarity       = vector_similarity(definition_embedding,\n",
    "                                                    prompt_embedding)\n",
    "        most_similar_summary    = definition    \n",
    "    else:\n",
    "        # Initialize a new column with NaN values\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            if pd.notna(row['embedding']).all():\n",
    "                df.at[index, 'prompt_similarity'] = vector_similarity(list(row['embedding']), prompt_embedding)\n",
    "\n",
    "        # get most similar summary\n",
    "        most_similar_summary = df.nlargest(1, 'prompt_similarity')['text'].values[0]\n",
    "        prompt_similarity = df.nlargest(1, 'prompt_similarity')['prompt_similarity'].values[0]\n",
    "\n",
    "    # Rest of your code...\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            You will act as an experienced Teacher, helping a student prepare for an exam.\n",
    "            I will provide you with a statement, and a the definition. \n",
    "            You will start your reply with a score from 0-100, in how close you evaluate it is to the definition.\n",
    "            If you based on the reading of the definition and statement, find a difference, then please reply with an argument for the discrepancy.\n",
    "            The format is:\n",
    "            eval_number/100 \\n [your reply]\n",
    "            Here is some context:\n",
    "            {most_similar_summary}\n",
    "            Q: {question} \\n\\n\n",
    "            A:\"\"\"\n",
    "    # Use OpenAI to get the most similar answer\n",
    "    response = openai.Completion.create(\n",
    "        engine = 'text-davinci-003', # Use the text-davinci-003 engine\n",
    "        prompt=prompt, # Use the prompt created above\n",
    "        temperature=0, # Set the temperature to 0\n",
    "        max_tokens=500, # Set the maximum tokens to 500\n",
    "        model=\"text-davinci-003\" # Use the text-davinci-003 model\n",
    "        )\n",
    "    response = response[\"choices\"][0][\"text\"].strip(\" \\n\")\n",
    "    print(prompt_similarity)\n",
    "    return response, most_similar_summary\n",
    "\n",
    "def set_embeddings(df, df_path):\n",
    "    if 'embeddings' in df.columns or 'embedding' in df.columns:\n",
    "        pass\n",
    "    else:\n",
    "        embedding = []\n",
    "        # Wrap the DataFrame's 'summary' column with tqdm to show progress bar\n",
    "        for text in tqdm(df['text'], desc=\"Getting embeddings\"):\n",
    "            new_embedding = get_embedding(text)\n",
    "            embedding.append(new_embedding)\n",
    "\n",
    "        # We need to do it again, because the recursion doesn't work fully\n",
    "        for i in tqdm(range(len(embedding))):\n",
    "            if embedding[i] == None:\n",
    "                summary = df.loc[i, 'text']\n",
    "                embedding[i] = get_embedding(summary)\n",
    "\n",
    "        df['embedding'] = embedding\n",
    "\n",
    "        df.to_csv(df_path, index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytlick\n"
     ]
    }
   ],
   "source": [
    "def print_performance(df, index):\n",
    "    score = df.at[index, 'last_score']\n",
    "    ps = df.at[index, 'last_ps']\n",
    "    df.to_csv('moves.csv', index=False)\n",
    "    if score > 90:\n",
    "        print(f\"Excellent job! You're mastering this material. DaVinci rated you {score}, Your PS value: \", ps)\n",
    "    elif score > 70:\n",
    "        print(f\"Good work! Keep practicing to improve even more. DaVinci rated you {score}, Your PS value: \", ps)\n",
    "    elif score > 50:\n",
    "        print(f\"You're making progress, but there's still room for improvement. DaVinci rated you {score}, Your PS value: \", ps)\n",
    "    else:\n",
    "        print(f\"Don't be discouraged. Keep studying and you'll get there! DaVinci rated you {score}, Your PS value: \", ps)\n",
    "\n",
    "def store_date(key,\n",
    "               text,\n",
    "               category,\n",
    "               embedding,\n",
    "               last_score,\n",
    "               last_runtime,\n",
    "               last_ps,\n",
    "               prompt_similarity):\n",
    "    path = 'storing_df.csv'\n",
    "    \n",
    "    storing_df = pd.read_csv(path)\n",
    "    storing_df.loc[len(storing_df)] = [key,\n",
    "                                        text,\n",
    "                                        category,\n",
    "                                        embedding,\n",
    "                                        last_score,\n",
    "                                        last_runtime,\n",
    "                                        last_ps,\n",
    "                                        prompt_similarity]\n",
    "    storing_df.to_csv(path, index=False)\n",
    "\n",
    "def find_rating(x: str):\n",
    "    if '100/100' in x:\n",
    "        return 100\n",
    "    elif x.startswith('0/100'):\n",
    "        return 0\n",
    "    else:\n",
    "        return re.findall('\\d{2}', x)[0]\n",
    "\n",
    "def key_embed_prompt_lookup(question: str, key: str, df: pd.DataFrame) -> str:\n",
    "    prompt_embedding = get_embedding(question)\n",
    "\n",
    "    df['prompt_similarity'] = np.nan  \n",
    "\n",
    "    if len(key) > 3:\n",
    "        \n",
    "        definition              = df[df.key == key].text.values[0]\n",
    "        definition_embedding    = df.loc[df.key == key, 'embedding'].values[0]\n",
    "        category                = df.loc[df.key == key, 'Category'].values[0]\n",
    "        prompt_similarity       = vector_similarity(definition_embedding,\n",
    "                                                    prompt_embedding)\n",
    "        most_similar_summary    = definition    \n",
    "    else:\n",
    "        # Initialize a new column with NaN values\n",
    "        for index, row in df.iterrows():\n",
    "            if pd.notna(row['embedding']).all():\n",
    "                df.at[index, 'prompt_similarity'] = vector_similarity(list(row['embedding']), prompt_embedding)\n",
    "\n",
    "        # get most similar summary\n",
    "        most_similar_summary = df.nlargest(1, 'prompt_similarity')['text'].values[0]\n",
    "        prompt_similarity = df.nlargest(1, 'prompt_similarity')['prompt_similarity'].values[0]\n",
    "        category           = df.nlargest(1, 'prompt_similarity')['Category'].values[0]    # Rest of your code...\n",
    "    \n",
    "    print(most_similar_summary)        \n",
    "    #messages = [{\"role\":\"system\",\"content\":\"You will act as an experienced Teacher, assisting a student in exam preparation. I will provide you with a statement, and a corresponding definition. Your role is to assess the degree of similarity between the statement and the definition on a precise scale from 0-100, accuracy is the key, so please be very precise in your response. In case you find any discrepancy between the statement and the definition, please articulate your observation as a coherent argument\"},\n",
    "    messages = [{\"role\":\"system\",\"content\":\"\"\"\n",
    "                 You will act as an experienced Active Recall Expert , assisting me in evaluating my statements compared to the definitions, or as in assisting a student in exam preparation.\n",
    "                 I will provide you with a statement, and a corresponding definition.\n",
    "                 Your role is to assess the degree of similarity between the statement and the definition on a precise scale from 0-100, accuracy is the key, so please be very precise in your response.\n",
    "                 In case you find any discrepancy between the statement and the definition, please articulate your observation as a coherent argument. \n",
    "                 If I reply I have no clue, please reply with a few hints to the answer, give me the score 0/100\n",
    "                 \"\"\"},\n",
    "                {\"role\":\"user\",\"content\":f\"I am studying Retrieval-Augmented Generation and Im currently researching the below question/term Why use Retrival-Augmented Generation?, which is defined as: \\n {'One of the core use cases of Large Language Models (LLMs) is question-answering over your own data. To do this, we pair the LLM with a “retrieval” model that can perform information retrieval over a knowledge corpus, and perform response synthesis over the retrieved texts using the LLM. This overall framework is called Retrieval-Augmented Generation.'} \\n I define it as: \\n Retrival-Augmented Generation is an extension of the typical embedding-retrival. However, by utilising LLM Retrival and embedding, we can get better performance, as the corpus of text provided for generation is greater, and can provide both the specific context and the global context \\n \"},\n",
    "                {\"role\":\"assistant\",\"content\":\"70/100. \\n\\nWhile your statement correctly highlights the use of LLMs in Retrieval-Augmented Generation and the benefits of utilizing a larger corpus of text for generation, it does not fully capture the core concept of the framework. Retrieval-Augmented Generation is not just an extension of embedding-retrieval, but rather a specific framework that involves pairing an LLM with a retrieval model to perform question-answering over a knowledge corpus. Additionally, your statement does not mention the synthesis of responses over the retrieved texts using the LLM, which is a key aspect of the framework.\"},\n",
    "                {\"role\":\"user\",\"content\":f\"I am studying Organisational Movements and Im currently need your help understanding the concept Pytlic, defined as: Making receivers of a presentation, guess what im thinking instead of providing or instructing them. Currently my understanding is: I dont know anything about it, can you give a hint\"},\n",
    "                {\"role\":\"assistant\",\"content\":\" 0/100 \\n\\n As you do not comprehend the definition at hand, your score is 0. \\n Pytlick is the organisational move, when a presenter is requesting the audience to guess what they are thinking, instead of providing the answer them selves\"},\n",
    "                {\"role\":\"user\",\"content\":f\"I am studying {category} and Im currently researching the below question/term {key}, which is defined as: \\n {most_similar_summary} \\n I define it as: \\n {question} \\n \"},\n",
    "                ]   \n",
    "         \n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id = 'gpt-35-turbo',\n",
    "        engine = 'gpt-35-turbo',\n",
    "        messages = messages,\n",
    "        temperature = 0.2,\n",
    "        max_tokens = 400,\n",
    "        top_p = 0.95,\n",
    "        frequency_penalty = 0,\n",
    "        presence_penalty = 0,\n",
    "        stop = None\n",
    "    )\n",
    "    response = response[\"choices\"][0]['message']['content']\n",
    "    print(prompt_similarity)\n",
    "    \n",
    "    ## Storing data for later retrieval\n",
    "    \n",
    "    store_date(key = key,\n",
    "               text = question,\n",
    "               category = df.loc[df.key == key, 'Category'].values[0],\n",
    "               embedding=prompt_embedding,\n",
    "               last_score=find_rating(response),\n",
    "               last_runtime=int(datetime.utcnow().timestamp()),\n",
    "               prompt_similarity =prompt_similarity,\n",
    "               last_ps=prompt_similarity)\n",
    "    \n",
    "    \n",
    "    return response, most_similar_summary,prompt_similarity\n",
    "\n",
    "response = ''\n",
    "\n",
    "def print_response(response = response):\n",
    "    lines = response.splitlines()\n",
    "    for line in lines:\n",
    "        if len(line) > 100:\n",
    "            sentences = line.split('. ')\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence + '.'\n",
    "                print(sentence) \n",
    "        else:\n",
    "            print(line)\n",
    "\n",
    "answer = 'I dont know'\n",
    "\n",
    "key = 'Pytlick'\n",
    "\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "      <th>embedding</th>\n",
       "      <th>last_score</th>\n",
       "      <th>last_runtime</th>\n",
       "      <th>last_ps</th>\n",
       "      <th>prompt_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeppesen</td>\n",
       "      <td>Asking about the process, saying how can we h...</td>\n",
       "      <td>Organisational Movements</td>\n",
       "      <td>[-0.008856984786689281, 0.014992808923125267, ...</td>\n",
       "      <td>90</td>\n",
       "      <td>1683728976</td>\n",
       "      <td>0.885209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why use Retrival-Augmented Generation?</td>\n",
       "      <td>One of the core use cases of Large Language Mo...</td>\n",
       "      <td>Retrieval-Augmented Generation</td>\n",
       "      <td>[-0.026878967881202698, 0.027037078514695168, ...</td>\n",
       "      <td>70</td>\n",
       "      <td>1683790635</td>\n",
       "      <td>0.886467</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How normal semantic synthesis is performed?</td>\n",
       "      <td>Most users building LLM-powered QA systems tod...</td>\n",
       "      <td>Retrieval-Augmented Generation</td>\n",
       "      <td>[0.003434924641624093, 0.025081591680645943, -...</td>\n",
       "      <td>50</td>\n",
       "      <td>1683867733</td>\n",
       "      <td>0.823933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the big pitfall with embedding-retrival?</td>\n",
       "      <td>Text chunks lack global context. Oftentimes th...</td>\n",
       "      <td>Retrieval-Augmented Generation</td>\n",
       "      <td>[0.008670363575220108, 0.007526219356805086, 0...</td>\n",
       "      <td>90</td>\n",
       "      <td>1683868201</td>\n",
       "      <td>0.859046</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the three big tuning issues with embe...</td>\n",
       "      <td>Careful tuning of top-k / similarity score thr...</td>\n",
       "      <td>Retrieval-Augmented Generation</td>\n",
       "      <td>[0.012233213521540165, -0.005706304218620062, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1683868329</td>\n",
       "      <td>0.728263</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>What is the basic concept of ChatGPT and why d...</td>\n",
       "      <td>So what would happen if we applied ChatGPT to ...</td>\n",
       "      <td>Generative Pre-trained Transformers</td>\n",
       "      <td>[-0.015013879165053368, 0.0011765881208702922,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>How does ChatGPT generate coherent human langu...</td>\n",
       "      <td>As we’ve seen, the actual neural net in ChatGP...</td>\n",
       "      <td>Generative Pre-trained Transformers</td>\n",
       "      <td>[-0.014149912633001804, 0.012706183828413486, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>How is ChatGPT able to generate human-like tex...</td>\n",
       "      <td>The specific engineering of ChatGPT has made i...</td>\n",
       "      <td>Generative Pre-trained Transformers</td>\n",
       "      <td>[-0.010274942964315414, 0.01824106089770794, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>How does the training strategy of ChatGPT diff...</td>\n",
       "      <td>When it comes to training (AKA learning) the d...</td>\n",
       "      <td>Generative Pre-trained Transformers</td>\n",
       "      <td>[-0.021468183025717735, 0.0143800163641572, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>What is the significance of ChatGPT in underst...</td>\n",
       "      <td>But for now it’s exciting to see what ChatGPT ...</td>\n",
       "      <td>Generative Pre-trained Transformers</td>\n",
       "      <td>[0.001286412589251995, 0.024362806230783463, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   key  \\\n",
       "0                                             Jeppesen   \n",
       "1               Why use Retrival-Augmented Generation?   \n",
       "2          How normal semantic synthesis is performed?   \n",
       "3     What is the big pitfall with embedding-retrival?   \n",
       "4    What are the three big tuning issues with embe...   \n",
       "..                                                 ...   \n",
       "225  What is the basic concept of ChatGPT and why d...   \n",
       "226  How does ChatGPT generate coherent human langu...   \n",
       "227  How is ChatGPT able to generate human-like tex...   \n",
       "228  How does the training strategy of ChatGPT diff...   \n",
       "229  What is the significance of ChatGPT in underst...   \n",
       "\n",
       "                                                  text  \\\n",
       "0     Asking about the process, saying how can we h...   \n",
       "1    One of the core use cases of Large Language Mo...   \n",
       "2    Most users building LLM-powered QA systems tod...   \n",
       "3    Text chunks lack global context. Oftentimes th...   \n",
       "4    Careful tuning of top-k / similarity score thr...   \n",
       "..                                                 ...   \n",
       "225  So what would happen if we applied ChatGPT to ...   \n",
       "226  As we’ve seen, the actual neural net in ChatGP...   \n",
       "227  The specific engineering of ChatGPT has made i...   \n",
       "228  When it comes to training (AKA learning) the d...   \n",
       "229  But for now it’s exciting to see what ChatGPT ...   \n",
       "\n",
       "                                Category  \\\n",
       "0               Organisational Movements   \n",
       "1         Retrieval-Augmented Generation   \n",
       "2         Retrieval-Augmented Generation   \n",
       "3         Retrieval-Augmented Generation   \n",
       "4         Retrieval-Augmented Generation   \n",
       "..                                   ...   \n",
       "225  Generative Pre-trained Transformers   \n",
       "226  Generative Pre-trained Transformers   \n",
       "227  Generative Pre-trained Transformers   \n",
       "228  Generative Pre-trained Transformers   \n",
       "229  Generative Pre-trained Transformers   \n",
       "\n",
       "                                             embedding  last_score  \\\n",
       "0    [-0.008856984786689281, 0.014992808923125267, ...          90   \n",
       "1    [-0.026878967881202698, 0.027037078514695168, ...          70   \n",
       "2    [0.003434924641624093, 0.025081591680645943, -...          50   \n",
       "3    [0.008670363575220108, 0.007526219356805086, 0...          90   \n",
       "4    [0.012233213521540165, -0.005706304218620062, ...          10   \n",
       "..                                                 ...         ...   \n",
       "225  [-0.015013879165053368, 0.0011765881208702922,...           0   \n",
       "226  [-0.014149912633001804, 0.012706183828413486, ...           0   \n",
       "227  [-0.010274942964315414, 0.01824106089770794, 0...           0   \n",
       "228  [-0.021468183025717735, 0.0143800163641572, 0....           0   \n",
       "229  [0.001286412589251995, 0.024362806230783463, 0...           0   \n",
       "\n",
       "     last_runtime   last_ps  prompt_similarity  \n",
       "0      1683728976  0.885209                NaN  \n",
       "1      1683790635  0.886467                NaN  \n",
       "2      1683867733  0.823933                NaN  \n",
       "3      1683868201  0.859046                NaN  \n",
       "4      1683868329  0.728263                NaN  \n",
       "..            ...       ...                ...  \n",
       "225             0  0.000000                NaN  \n",
       "226             0  0.000000                NaN  \n",
       "227             0  0.000000                NaN  \n",
       "228             0  0.000000                NaN  \n",
       "229             0  0.000000                NaN  \n",
       "\n",
       "[230 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = my_reader('moves.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>summary</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>Author</th>\n",
       "      <th>last_score</th>\n",
       "      <th>last_run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tool Moderate Exercise before cognetive:</td>\n",
       "      <td>that I think you will find particularly intere...</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>The study titled \"Brief Aerobic Exercise Immed...</td>\n",
       "      <td>What did the study by Legrand et al. find abou...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>100</td>\n",
       "      <td>1685322425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Circadian Rhythm &amp; Body Temperature:</td>\n",
       "      <td>Let's talk about the use of cold for health an...</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>The use of cold for health and performance has...</td>\n",
       "      <td>What is the relationship between deliberate co...</td>\n",
       "      <td>90</td>\n",
       "      <td>1684714574</td>\n",
       "      <td>1</td>\n",
       "      <td>1685322434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tool: Quickly Decrease Core Body Temperature, ...</td>\n",
       "      <td>So that's the circadian rhythm in temperature....</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>Andrew huberman explains how the thermal regul...</td>\n",
       "      <td>How would the body react to getting cold water...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>0</td>\n",
       "      <td>1685321333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What I'll tell you, and we'll get into this in...</td>\n",
       "      <td>We're going to talk more about the specific pr...</td>\n",
       "      <td>3095.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>The main takeaways from this lecture are that ...</td>\n",
       "      <td>What are the main takeaways from Andrew Huberm...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>0</td>\n",
       "      <td>1684715097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mental Effects of Cold Exposure::</td>\n",
       "      <td>Mental Effects of Cold Exposure: And I want to...</td>\n",
       "      <td>3282.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>Deliberate cold exposure can improve mental pe...</td>\n",
       "      <td>What are the benefits of deliberate cold expos...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>80</td>\n",
       "      <td>1684715321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Physical Effects of Cold Exposure:</td>\n",
       "      <td>but deliberate cold exposure has also been stu...</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>Deliberate cold exposure has been studied in a...</td>\n",
       "      <td>What are the potential benefits of deliberate ...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>80</td>\n",
       "      <td>1684715790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How Cold Should the Temperature Be?:</td>\n",
       "      <td>but where I'd like to start is with mental per...</td>\n",
       "      <td>4934.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the key point that Andrew Huberman mak...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cold Showers vs. Cold Water Immersion:</td>\n",
       "      <td>cold showers are as good, better or worse than...</td>\n",
       "      <td>3756.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>Cold water immersion up to the neck with hands...</td>\n",
       "      <td>What are the most effective forms of cold expo...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>0</td>\n",
       "      <td>1684715885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Protocols for Cold Exposure:</td>\n",
       "      <td>and performance using deliberate cold exposure...</td>\n",
       "      <td>12897.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>Deliberate cold exposure can increase norepine...</td>\n",
       "      <td>What is the recommended approach for increasin...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>90</td>\n",
       "      <td>1684716011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optimal Mindset(s) During Cold Exposure:</td>\n",
       "      <td>The next question that I always get is what sh...</td>\n",
       "      <td>4796.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>is the importance of gradually increasing the ...</td>\n",
       "      <td>What are the potential hazards of deliberate c...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>80</td>\n",
       "      <td>1684716089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tool: Using Movement During Cold Exposure:</td>\n",
       "      <td>that I rarely if ever hear discussed, but is v...</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>When doing deliberate cold exposure, it is imp...</td>\n",
       "      <td>What are the benefits of moving around continu...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>80</td>\n",
       "      <td>1684716208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Optimal Frequency of Cold Exposure:</td>\n",
       "      <td>Another very common question is how often to d...</td>\n",
       "      <td>2673.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>The recommended threshold for deliberate cold ...</td>\n",
       "      <td>What is the recommended threshold for delibera...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>50</td>\n",
       "      <td>1684716348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cold Exposure for Dopamine, Mood &amp; Focus:</td>\n",
       "      <td>for sake of building resilience, which I do be...</td>\n",
       "      <td>12022.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are the effects of deliberate cold exposu...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cold Exposure &amp; Metabolism, Brown Fat:</td>\n",
       "      <td>And I'd like to start by detailing a study tha...</td>\n",
       "      <td>12213.0</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>This study looked at deliberate cold exposure ...</td>\n",
       "      <td>What are the benefits of deliberate cold expos...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>20</td>\n",
       "      <td>1684716723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tool: Caffeine                                ...</td>\n",
       "      <td>to increase dopamine levels in your brain and ...</td>\n",
       "      <td>3641.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>:\\r\\n\\r\\n- To increase dopamine levels, you ca...</td>\n",
       "      <td>What is the relationship between caffeine inge...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>1</td>\n",
       "      <td>1684716858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tools: Increasing Metabolism w/Cold – The Søbe...</td>\n",
       "      <td>in thinking about deliberate cold exposure and...</td>\n",
       "      <td>4869.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>The Søberg principle, named after Dr. Susanna ...</td>\n",
       "      <td>What is the Søberg principle and how does it s...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>10</td>\n",
       "      <td>1684717011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Norepinephrine &amp; Fat Cells:</td>\n",
       "      <td>So up until now, I've been talking about delib...</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>as a potential therapy for various health cond...</td>\n",
       "      <td>What are the potential benefits and risks asso...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>90</td>\n",
       "      <td>1684717116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cold, Physical Performance, Inflammation:</td>\n",
       "      <td>for sake of physical performance. And there ar...</td>\n",
       "      <td>10998.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>which is the importance of not getting too neu...</td>\n",
       "      <td>What are the benefits of cold water immersion ...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>50</td>\n",
       "      <td>1684717240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hyperthermia &amp; Glabrous Skin Cooling:</td>\n",
       "      <td>which are those glabrous skin surfaces, the ha...</td>\n",
       "      <td>5745.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>Glabrous skin surfaces, such as the palms, sol...</td>\n",
       "      <td>What is the Søberg Principle and how does it r...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>10</td>\n",
       "      <td>1684717395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tool: Palmar Cooling &amp; Endurance:</td>\n",
       "      <td>are truly remarkable provided the glabrous ski...</td>\n",
       "      <td>10154.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>Palmer cooling can significantly improve endur...</td>\n",
       "      <td>According to Andrew Huberman, how can palmer c...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>70</td>\n",
       "      <td>1684717499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tool: Optimal Timing for Daily Cold Exposure:</td>\n",
       "      <td>Now I promise you the last topic was the last ...</td>\n",
       "      <td>3506.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>the main takeaway is that deliberate cold expo...</td>\n",
       "      <td>What are the potential benefits and drawbacks ...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman</td>\n",
       "      <td>20</td>\n",
       "      <td>1684717606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tool Moderate Exercise before cognetive:</td>\n",
       "      <td>that I think you will find particularly intere...</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>The study titled \"Brief Aerobic Exercise Immed...</td>\n",
       "      <td>What is the main finding of the study \"Brief A...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1684717696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Circadian Rhythm &amp; Body Temperature:</td>\n",
       "      <td>Let's talk about the use of cold for health an...</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>The use of cold for health and performance has...</td>\n",
       "      <td>What is the relationship between deliberate co...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>10</td>\n",
       "      <td>1684717800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tool: Quickly Decrease Core Body Temperature, ...</td>\n",
       "      <td>What I'll tell you, and we'll get into this in...</td>\n",
       "      <td>6680.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>The approach to cooling the body is to utilise...</td>\n",
       "      <td>What is the best practice to cool a very hot p...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685321494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mental Effects of Cold Exposure:</td>\n",
       "      <td>And I want to separate those out for you. Ther...</td>\n",
       "      <td>3249.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>but there are also physical benefits. Cold exp...</td>\n",
       "      <td>What are the potential physical benefits of de...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1684717986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Physical Effects of Cold Exposure:</td>\n",
       "      <td>but deliberate cold exposure has also been stu...</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>Deliberate cold exposure has been studied in a...</td>\n",
       "      <td>What are the potential benefits of deliberate ...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>100</td>\n",
       "      <td>1684718067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How Cold Should the Temperature Be?:</td>\n",
       "      <td>but where I'd like to start is with mental per...</td>\n",
       "      <td>4934.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the key point that Andrew Huberman and...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cold Showers vs. Cold Water Immersion:</td>\n",
       "      <td>cold showers are as good, better or worse than...</td>\n",
       "      <td>3756.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>Cold water immersion up to the neck with hands...</td>\n",
       "      <td>What are the most effective forms of cold expo...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>80</td>\n",
       "      <td>1684718099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Protocols for Cold Exposure:</td>\n",
       "      <td>and performance using deliberate cold exposure...</td>\n",
       "      <td>12897.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>Deliberate cold exposure can increase norepine...</td>\n",
       "      <td>What is the recommended approach for increasin...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>50</td>\n",
       "      <td>1684718201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Optimal Mindset(s) During Cold Exposure:</td>\n",
       "      <td>The next question that I always get is what sh...</td>\n",
       "      <td>4796.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>is the importance of gradually increasing the ...</td>\n",
       "      <td>What are the potential hazards of deliberate c...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685289743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tool: Using Movement During Cold Exposure:</td>\n",
       "      <td>that I rarely if ever hear discussed, but is v...</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>When doing deliberate cold exposure, it is imp...</td>\n",
       "      <td>What are the benefits of moving around continu...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>70</td>\n",
       "      <td>1685289826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Optimal Frequency of Cold Exposure:</td>\n",
       "      <td>Another very common question is how often to d...</td>\n",
       "      <td>2673.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>The recommended threshold for deliberate cold ...</td>\n",
       "      <td>What is the recommended threshold for delibera...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685289961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cold Exposure for Dopamine, Mood &amp; Focus:</td>\n",
       "      <td>for sake of building resilience, which I do be...</td>\n",
       "      <td>12022.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are the effects of deliberate cold exposu...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cold Exposure &amp; Metabolism, Brown Fat:</td>\n",
       "      <td>And I'd like to start by detailing a study tha...</td>\n",
       "      <td>12213.0</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>This study looked at deliberate cold exposure ...</td>\n",
       "      <td>According to Andrew Huberman and Susanna Søber...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>50</td>\n",
       "      <td>1685290058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Tool: Caffeine, Dopamine &amp; Cold Exposure:</td>\n",
       "      <td>to increase dopamine levels in your brain and ...</td>\n",
       "      <td>3641.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>:\\r\\n\\r\\n- Ingesting caffeine 60 to 120 minute...</td>\n",
       "      <td>What are the potential benefits of ingesting c...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685290241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Tools: Increasing Metabolism w/Cold – The Søbe...</td>\n",
       "      <td>in thinking about deliberate cold exposure and...</td>\n",
       "      <td>4869.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>The Søberg principle, named after Dr. Susanna ...</td>\n",
       "      <td>What is the Søberg principle and how does it s...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685290446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Norepinephrine &amp; Fat Cells:</td>\n",
       "      <td>So up until now, I've been talking about delib...</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>as a potential therapy for various health cond...</td>\n",
       "      <td>What are the potential benefits and hazards as...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685291039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cold, Physical Performance, Inflammation:</td>\n",
       "      <td>for sake of physical performance. And there ar...</td>\n",
       "      <td>10998.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are the general guidelines for using deli...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Hyperthermia &amp; Glabrous Skin Cooling:</td>\n",
       "      <td>which are those glabrous skin surfaces, the ha...</td>\n",
       "      <td>5745.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>Glabrous skin surfaces, such as the palms, sol...</td>\n",
       "      <td>What is the Søberg Principle, and how can it b...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>0</td>\n",
       "      <td>1685314024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Tool: Palmar Cooling &amp; Endurance:</td>\n",
       "      <td>are truly remarkable provided the glabrous ski...</td>\n",
       "      <td>10154.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>Palmer cooling can significantly improve endur...</td>\n",
       "      <td>According to Andrew Huberman and Susanna Søber...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>90</td>\n",
       "      <td>1685321747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Cold Exposure to Groin, Increasing Testosterone:</td>\n",
       "      <td>and performance, I'd like to touch on this the...</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1)The practice of using deliberate cold exposu...</td>\n",
       "      <td>Does cold exposure to the groin area only affe...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>50</td>\n",
       "      <td>1685321834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tool: Optimal Timing for Daily Cold Exposure:</td>\n",
       "      <td>Now I promise you the last topic was the last ...</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>the main takeaway is that deliberate cold expo...</td>\n",
       "      <td>What are the potential benefits and drawbacks ...</td>\n",
       "      <td>Cold Exposure</td>\n",
       "      <td>Andrew Huberman and Susanna Søberg</td>\n",
       "      <td>20</td>\n",
       "      <td>1685321928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               header  \\\n",
       "0            Tool Moderate Exercise before cognetive:   \n",
       "1                Circadian Rhythm & Body Temperature:   \n",
       "2   Tool: Quickly Decrease Core Body Temperature, ...   \n",
       "3   What I'll tell you, and we'll get into this in...   \n",
       "4                   Mental Effects of Cold Exposure::   \n",
       "5                  Physical Effects of Cold Exposure:   \n",
       "6                How Cold Should the Temperature Be?:   \n",
       "7              Cold Showers vs. Cold Water Immersion:   \n",
       "8                        Protocols for Cold Exposure:   \n",
       "9            Optimal Mindset(s) During Cold Exposure:   \n",
       "10         Tool: Using Movement During Cold Exposure:   \n",
       "11                Optimal Frequency of Cold Exposure:   \n",
       "12          Cold Exposure for Dopamine, Mood & Focus:   \n",
       "13             Cold Exposure & Metabolism, Brown Fat:   \n",
       "14  Tool: Caffeine                                ...   \n",
       "15  Tools: Increasing Metabolism w/Cold – The Søbe...   \n",
       "16                        Norepinephrine & Fat Cells:   \n",
       "17          Cold, Physical Performance, Inflammation:   \n",
       "18              Hyperthermia & Glabrous Skin Cooling:   \n",
       "19                  Tool: Palmar Cooling & Endurance:   \n",
       "20      Tool: Optimal Timing for Daily Cold Exposure:   \n",
       "21           Tool Moderate Exercise before cognetive:   \n",
       "22               Circadian Rhythm & Body Temperature:   \n",
       "23  Tool: Quickly Decrease Core Body Temperature, ...   \n",
       "24                   Mental Effects of Cold Exposure:   \n",
       "25                 Physical Effects of Cold Exposure:   \n",
       "26               How Cold Should the Temperature Be?:   \n",
       "27             Cold Showers vs. Cold Water Immersion:   \n",
       "28                       Protocols for Cold Exposure:   \n",
       "29           Optimal Mindset(s) During Cold Exposure:   \n",
       "30         Tool: Using Movement During Cold Exposure:   \n",
       "31                Optimal Frequency of Cold Exposure:   \n",
       "32          Cold Exposure for Dopamine, Mood & Focus:   \n",
       "33             Cold Exposure & Metabolism, Brown Fat:   \n",
       "34          Tool: Caffeine, Dopamine & Cold Exposure:   \n",
       "35  Tools: Increasing Metabolism w/Cold – The Søbe...   \n",
       "36                        Norepinephrine & Fat Cells:   \n",
       "37          Cold, Physical Performance, Inflammation:   \n",
       "38              Hyperthermia & Glabrous Skin Cooling:   \n",
       "39                  Tool: Palmar Cooling & Endurance:   \n",
       "40   Cold Exposure to Groin, Increasing Testosterone:   \n",
       "41      Tool: Optimal Timing for Daily Cold Exposure:   \n",
       "\n",
       "                                                 text   length  tokens  \\\n",
       "0   that I think you will find particularly intere...   6501.0  1305.0   \n",
       "1   Let's talk about the use of cold for health an...   2798.0   569.0   \n",
       "2   So that's the circadian rhythm in temperature....   3195.0   694.0   \n",
       "3   We're going to talk more about the specific pr...   3095.0   652.0   \n",
       "4   Mental Effects of Cold Exposure: And I want to...   3282.0   696.0   \n",
       "5   but deliberate cold exposure has also been stu...   1253.0   252.0   \n",
       "6   but where I'd like to start is with mental per...   4934.0  1030.0   \n",
       "7   cold showers are as good, better or worse than...   3756.0   806.0   \n",
       "8   and performance using deliberate cold exposure...  12897.0  2773.0   \n",
       "9   The next question that I always get is what sh...   4796.0   976.0   \n",
       "10  that I rarely if ever hear discussed, but is v...   2505.0   537.0   \n",
       "11  Another very common question is how often to d...   2673.0   549.0   \n",
       "12  for sake of building resilience, which I do be...  12022.0  2506.0   \n",
       "13  And I'd like to start by detailing a study tha...  12213.0  2466.0   \n",
       "14  to increase dopamine levels in your brain and ...   3641.0   754.0   \n",
       "15  in thinking about deliberate cold exposure and...   4869.0  1033.0   \n",
       "16  So up until now, I've been talking about delib...   2144.0   455.0   \n",
       "17  for sake of physical performance. And there ar...  10998.0  2096.0   \n",
       "18  which are those glabrous skin surfaces, the ha...   5745.0  1231.0   \n",
       "19  are truly remarkable provided the glabrous ski...  10154.0  2111.0   \n",
       "20  Now I promise you the last topic was the last ...   3506.0   747.0   \n",
       "21  that I think you will find particularly intere...   6501.0  1305.0   \n",
       "22  Let's talk about the use of cold for health an...   1202.0   244.0   \n",
       "23  What I'll tell you, and we'll get into this in...   6680.0  1425.0   \n",
       "24  And I want to separate those out for you. Ther...   3249.0   689.0   \n",
       "25  but deliberate cold exposure has also been stu...   1253.0   252.0   \n",
       "26  but where I'd like to start is with mental per...   4934.0  1030.0   \n",
       "27  cold showers are as good, better or worse than...   3756.0   806.0   \n",
       "28  and performance using deliberate cold exposure...  12897.0  2773.0   \n",
       "29  The next question that I always get is what sh...   4796.0   976.0   \n",
       "30  that I rarely if ever hear discussed, but is v...   2505.0   537.0   \n",
       "31  Another very common question is how often to d...   2673.0   549.0   \n",
       "32  for sake of building resilience, which I do be...  12022.0  2506.0   \n",
       "33  And I'd like to start by detailing a study tha...  12213.0  2466.0   \n",
       "34  to increase dopamine levels in your brain and ...   3641.0   754.0   \n",
       "35  in thinking about deliberate cold exposure and...   4869.0  1033.0   \n",
       "36  So up until now, I've been talking about delib...   2144.0   455.0   \n",
       "37  for sake of physical performance. And there ar...  10998.0  2096.0   \n",
       "38  which are those glabrous skin surfaces, the ha...   5745.0  1231.0   \n",
       "39  are truly remarkable provided the glabrous ski...  10154.0  2111.0   \n",
       "40  and performance, I'd like to touch on this the...   4385.0   874.0   \n",
       "41  Now I promise you the last topic was the last ...   1316.0   266.0   \n",
       "\n",
       "                                              summary  \\\n",
       "0   The study titled \"Brief Aerobic Exercise Immed...   \n",
       "1   The use of cold for health and performance has...   \n",
       "2   Andrew huberman explains how the thermal regul...   \n",
       "3   The main takeaways from this lecture are that ...   \n",
       "4   Deliberate cold exposure can improve mental pe...   \n",
       "5   Deliberate cold exposure has been studied in a...   \n",
       "6                                                 NaN   \n",
       "7   Cold water immersion up to the neck with hands...   \n",
       "8   Deliberate cold exposure can increase norepine...   \n",
       "9   is the importance of gradually increasing the ...   \n",
       "10  When doing deliberate cold exposure, it is imp...   \n",
       "11  The recommended threshold for deliberate cold ...   \n",
       "12                                                NaN   \n",
       "13  This study looked at deliberate cold exposure ...   \n",
       "14  :\\r\\n\\r\\n- To increase dopamine levels, you ca...   \n",
       "15  The Søberg principle, named after Dr. Susanna ...   \n",
       "16  as a potential therapy for various health cond...   \n",
       "17  which is the importance of not getting too neu...   \n",
       "18  Glabrous skin surfaces, such as the palms, sol...   \n",
       "19  Palmer cooling can significantly improve endur...   \n",
       "20  the main takeaway is that deliberate cold expo...   \n",
       "21  The study titled \"Brief Aerobic Exercise Immed...   \n",
       "22  The use of cold for health and performance has...   \n",
       "23  The approach to cooling the body is to utilise...   \n",
       "24  but there are also physical benefits. Cold exp...   \n",
       "25  Deliberate cold exposure has been studied in a...   \n",
       "26                                                NaN   \n",
       "27  Cold water immersion up to the neck with hands...   \n",
       "28  Deliberate cold exposure can increase norepine...   \n",
       "29  is the importance of gradually increasing the ...   \n",
       "30  When doing deliberate cold exposure, it is imp...   \n",
       "31  The recommended threshold for deliberate cold ...   \n",
       "32                                                NaN   \n",
       "33  This study looked at deliberate cold exposure ...   \n",
       "34  :\\r\\n\\r\\n- Ingesting caffeine 60 to 120 minute...   \n",
       "35  The Søberg principle, named after Dr. Susanna ...   \n",
       "36  as a potential therapy for various health cond...   \n",
       "37                                                NaN   \n",
       "38  Glabrous skin surfaces, such as the palms, sol...   \n",
       "39  Palmer cooling can significantly improve endur...   \n",
       "40  1)The practice of using deliberate cold exposu...   \n",
       "41  the main takeaway is that deliberate cold expo...   \n",
       "\n",
       "                                             question       category  \\\n",
       "0   What did the study by Legrand et al. find abou...  Cold Exposure   \n",
       "1   What is the relationship between deliberate co...             90   \n",
       "2   How would the body react to getting cold water...  Cold Exposure   \n",
       "3   What are the main takeaways from Andrew Huberm...  Cold Exposure   \n",
       "4   What are the benefits of deliberate cold expos...  Cold Exposure   \n",
       "5   What are the potential benefits of deliberate ...  Cold Exposure   \n",
       "6   What is the key point that Andrew Huberman mak...  Cold Exposure   \n",
       "7   What are the most effective forms of cold expo...  Cold Exposure   \n",
       "8   What is the recommended approach for increasin...  Cold Exposure   \n",
       "9   What are the potential hazards of deliberate c...  Cold Exposure   \n",
       "10  What are the benefits of moving around continu...  Cold Exposure   \n",
       "11  What is the recommended threshold for delibera...  Cold Exposure   \n",
       "12  What are the effects of deliberate cold exposu...  Cold Exposure   \n",
       "13  What are the benefits of deliberate cold expos...  Cold Exposure   \n",
       "14  What is the relationship between caffeine inge...  Cold Exposure   \n",
       "15  What is the Søberg principle and how does it s...  Cold Exposure   \n",
       "16  What are the potential benefits and risks asso...  Cold Exposure   \n",
       "17  What are the benefits of cold water immersion ...  Cold Exposure   \n",
       "18  What is the Søberg Principle and how does it r...  Cold Exposure   \n",
       "19  According to Andrew Huberman, how can palmer c...  Cold Exposure   \n",
       "20  What are the potential benefits and drawbacks ...  Cold Exposure   \n",
       "21  What is the main finding of the study \"Brief A...  Cold Exposure   \n",
       "22  What is the relationship between deliberate co...  Cold Exposure   \n",
       "23  What is the best practice to cool a very hot p...  Cold Exposure   \n",
       "24  What are the potential physical benefits of de...  Cold Exposure   \n",
       "25  What are the potential benefits of deliberate ...  Cold Exposure   \n",
       "26  What is the key point that Andrew Huberman and...  Cold Exposure   \n",
       "27  What are the most effective forms of cold expo...  Cold Exposure   \n",
       "28  What is the recommended approach for increasin...  Cold Exposure   \n",
       "29  What are the potential hazards of deliberate c...  Cold Exposure   \n",
       "30  What are the benefits of moving around continu...  Cold Exposure   \n",
       "31  What is the recommended threshold for delibera...  Cold Exposure   \n",
       "32  What are the effects of deliberate cold exposu...  Cold Exposure   \n",
       "33  According to Andrew Huberman and Susanna Søber...  Cold Exposure   \n",
       "34  What are the potential benefits of ingesting c...  Cold Exposure   \n",
       "35  What is the Søberg principle and how does it s...  Cold Exposure   \n",
       "36  What are the potential benefits and hazards as...  Cold Exposure   \n",
       "37  What are the general guidelines for using deli...  Cold Exposure   \n",
       "38  What is the Søberg Principle, and how can it b...  Cold Exposure   \n",
       "39  According to Andrew Huberman and Susanna Søber...  Cold Exposure   \n",
       "40  Does cold exposure to the groin area only affe...  Cold Exposure   \n",
       "41  What are the potential benefits and drawbacks ...  Cold Exposure   \n",
       "\n",
       "                                Author  last_score    last_run  \n",
       "0                      Andrew Huberman         100  1685322425  \n",
       "1                           1684714574           1  1685322434  \n",
       "2                      Andrew Huberman           0  1685321333  \n",
       "3                      Andrew Huberman           0  1684715097  \n",
       "4                      Andrew Huberman          80  1684715321  \n",
       "5                      Andrew Huberman          80  1684715790  \n",
       "6                      Andrew Huberman           0           0  \n",
       "7                      Andrew Huberman           0  1684715885  \n",
       "8                      Andrew Huberman          90  1684716011  \n",
       "9                      Andrew Huberman          80  1684716089  \n",
       "10                     Andrew Huberman          80  1684716208  \n",
       "11                     Andrew Huberman          50  1684716348  \n",
       "12                     Andrew Huberman           0           0  \n",
       "13                     Andrew Huberman          20  1684716723  \n",
       "14                     Andrew Huberman           1  1684716858  \n",
       "15                     Andrew Huberman          10  1684717011  \n",
       "16                     Andrew Huberman          90  1684717116  \n",
       "17                     Andrew Huberman          50  1684717240  \n",
       "18                     Andrew Huberman          10  1684717395  \n",
       "19                     Andrew Huberman          70  1684717499  \n",
       "20                     Andrew Huberman          20  1684717606  \n",
       "21  Andrew Huberman and Susanna Søberg          90  1684717696  \n",
       "22  Andrew Huberman and Susanna Søberg          10  1684717800  \n",
       "23  Andrew Huberman and Susanna Søberg          90  1685321494  \n",
       "24  Andrew Huberman and Susanna Søberg          90  1684717986  \n",
       "25  Andrew Huberman and Susanna Søberg         100  1684718067  \n",
       "26  Andrew Huberman and Susanna Søberg           0           0  \n",
       "27  Andrew Huberman and Susanna Søberg          80  1684718099  \n",
       "28  Andrew Huberman and Susanna Søberg          50  1684718201  \n",
       "29  Andrew Huberman and Susanna Søberg          90  1685289743  \n",
       "30  Andrew Huberman and Susanna Søberg          70  1685289826  \n",
       "31  Andrew Huberman and Susanna Søberg          90  1685289961  \n",
       "32  Andrew Huberman and Susanna Søberg           0           0  \n",
       "33  Andrew Huberman and Susanna Søberg          50  1685290058  \n",
       "34  Andrew Huberman and Susanna Søberg          90  1685290241  \n",
       "35  Andrew Huberman and Susanna Søberg          90  1685290446  \n",
       "36  Andrew Huberman and Susanna Søberg          90  1685291039  \n",
       "37  Andrew Huberman and Susanna Søberg           0           0  \n",
       "38  Andrew Huberman and Susanna Søberg           0  1685314024  \n",
       "39  Andrew Huberman and Susanna Søberg          90  1685321747  \n",
       "40  Andrew Huberman and Susanna Søberg          50  1685321834  \n",
       "41  Andrew Huberman and Susanna Søberg          20  1685321928  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv('data.csv')\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        x = df.loc[i]\n",
    "        header = \"\"\n",
    "        text = x['text']\n",
    "        length = len(x['text'])\n",
    "        tokens = int(len(x['text'])/4)\n",
    "        summary = \"\"\n",
    "        question = x['key']\n",
    "        author = \"\"\n",
    "        category = x['Category'] \n",
    "        last_score = x['last_score']\n",
    "        last_run = x['last_runtime']\n",
    "        \n",
    "        new_df.loc[len(new_df)] = [header, text, length, tokens, summary, question, category, author, last_score, last_run]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "im working\n",
      "2 0 0\n",
      "0\n",
      "im working\n",
      " 0 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m             m_rec(x, y, j)\n\u001b[0;32m    117\u001b[0m     j \u001b[39m=\u001b[39m j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \n\u001b[1;32m--> 119\u001b[0m m_rec(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, y \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, j \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[93], line 116\u001b[0m, in \u001b[0;36mm_rec\u001b[1;34m(x, y, j)\u001b[0m\n\u001b[0;32m    114\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\n\u001b[0;32m    115\u001b[0m         \u001b[39mprint\u001b[39m(x, y, j)\n\u001b[1;32m--> 116\u001b[0m         m_rec(x, y, j)\n\u001b[0;32m    117\u001b[0m j \u001b[39m=\u001b[39m j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[93], line 116\u001b[0m, in \u001b[0;36mm_rec\u001b[1;34m(x, y, j)\u001b[0m\n\u001b[0;32m    114\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\n\u001b[0;32m    115\u001b[0m         \u001b[39mprint\u001b[39m(x, y, j)\n\u001b[1;32m--> 116\u001b[0m         m_rec(x, y, j)\n\u001b[0;32m    117\u001b[0m j \u001b[39m=\u001b[39m j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[93], line 100\u001b[0m, in \u001b[0;36mm_rec\u001b[1;34m(x, y, j)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mm_rec\u001b[39m(x \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, y: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, j: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 100\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m()\n\u001b[0;32m    103\u001b[0m     y , x  \u001b[39m=\u001b[39m marseille_api_call(problem \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhej\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    104\u001b[0m                                 key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnot my problem\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    105\u001b[0m                                 j \u001b[39m=\u001b[39m j)\n\u001b[0;32m    106\u001b[0m     \u001b[39mprint\u001b[39m(j)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py:1182\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1181\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1183\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1184\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1186\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1187\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py:1225\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1225\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def message_cleaner(messages:list = messages) -> list:\n",
    "    tmp = []\n",
    "\n",
    "    for j in messages:\n",
    "        new_line = {'role': '',\n",
    "                    'content': ''}\n",
    "        for k in j:\n",
    "            if k == 'content':\n",
    "                x = re.sub(' {2,}', '', j[k])\n",
    "                x = x.strip()\n",
    "                new_line['content'] = x \n",
    "            else: \n",
    "                new_line['role'] = j[k]\n",
    "                \n",
    "        tmp.append(new_line)\n",
    "                \n",
    "    return tmp\n",
    "\n",
    "def api_call(y = ''):\n",
    "    x = random.randint(0, 100)\n",
    "    \n",
    "    return x , y\n",
    "\n",
    "def marseille_api_call(problem = '', key = '', j = ''):\n",
    "    #x = random.randint(0, 100)\n",
    "    x = 0\n",
    "    messages = [{\"role\":\"system\",\"content\":\"\"\"\n",
    "                I want you to act as a SQL Teacher.\n",
    "                You will assist me with my questions, by giving me hints to the correct solution to my questions. \n",
    "                I will try three times each, and then you will give me the solution, i will start each message with my attempt number.\n",
    "                Once i reach the solution you will and explain step by step what happens in the key.\n",
    "                You should use your knowledge of SQL and database management to provide me with the best solutions.\n",
    "                In the event, that i write a solution which solves the problem, but is not the best solution, please congratulate me, and then write the best practice. \n",
    "                \n",
    "                Here is an example \n",
    "                User:\n",
    "                Attempt: 1\n",
    "                Problem: Finding the amount of orders completed within a period\n",
    "                Key: \n",
    "                Select orders, timestamp, and product_sku\n",
    "                From table;\n",
    "                \n",
    "                Assistant:\n",
    "                Nice job, you got the correct values, however to get the count you need to use the COUNT function\n",
    "                \n",
    "                User:\n",
    "                Attempt: 2\n",
    "                Problem: Finding the amount of orders completed within a period\n",
    "                Key: \n",
    "                Select count(orders) as order,\n",
    "                product_sku as product,\n",
    "                timestamp as timestamp\n",
    "                from \n",
    "                table\n",
    "                where timestamp between 07-05-2023 and 15-05-2023\n",
    "                order by product;\n",
    "                \n",
    "                Assistant:\n",
    "                Great job! You got it \n",
    "                \"\"\"},\n",
    "                {'role': 'user', \n",
    "                 'content': f'Attempt: {j}\\nProblem: {problem}\\n: Key: {key}'}\n",
    "                ] \n",
    "\n",
    "    messages = message_cleaner(messages=messages)\n",
    "    \n",
    "    y = ''\n",
    "    return x , y\n",
    "\n",
    "def brute_sleep(release_int = 5):\n",
    "    now = int(datetime.utcnow().timestamp())\n",
    "    release = now + release_int\n",
    "    print('im working')\n",
    "    while now <= release:\n",
    "        now = int(datetime.utcnow().timestamp())\n",
    "\n",
    "def api_rec(x = '', y: int = 0, j: int = 0):\n",
    "    if x == '':\n",
    "        x = input()\n",
    "    \n",
    "    \n",
    "    y , x  = api_call(y = x)\n",
    "    print(j)\n",
    "    if j >= 3:\n",
    "        print( 'to many attempts')\n",
    "    else: \n",
    "        if y > 70:\n",
    "            print(y, x)\n",
    "        else:\n",
    "            x = input()\n",
    "            j = j + 1 \n",
    "            print(x, y, j)\n",
    "            apo_rec(x, y, j)\n",
    "\n",
    "def m_rec(x = '', y: int = 0, j: int = 0):\n",
    "    if x == '':\n",
    "        x = input()\n",
    "    \n",
    "    \n",
    "    y , x  = marseille_api_call(problem = 'hej',\n",
    "                                key = 'not my problem',\n",
    "                                j = j)\n",
    "    print(j)\n",
    "    if j >= 3:\n",
    "        print( 'to many attempts')\n",
    "    else: \n",
    "        if y > 70:\n",
    "            print(y, x)\n",
    "        else:\n",
    "            brute_sleep(3)\n",
    "            x = input()\n",
    "            print(x, y, j)\n",
    "            m_rec(x, y, j)\n",
    "            j = j + 1 \n",
    "            \n",
    "m_rec('', y = 1, j = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SKU Number</td>\n",
       "      <td>https://purview.microsoft.com/datacatalog/gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Description</td>\n",
       "      <td>[Product Platform Document or Description -&gt; h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Part Type</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Group Code</td>\n",
       "      <td>https://purview.microsoft.com/datacatalog/gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Type Code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Item Group (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Item Sales Tax Group (Local)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Financial Dimensions (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Comodity Code --&gt; UN Commodity Code (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Country/Region --&gt; Country of Origin/ISO Locat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1                                                  2  \\\n",
       "0    Product        NaN                                         SKU Number   \n",
       "1    Product        NaN                                Product Description   \n",
       "2    Product        NaN                                          Part Type   \n",
       "3    Product        NaN                                 Product Group Code   \n",
       "4    Product        NaN                                  Product Type Code   \n",
       "..       ...        ...                                                ...   \n",
       "126  Product  Financial                                Item Group (Global)   \n",
       "127  Product  Financial                       Item Sales Tax Group (Local)   \n",
       "128  Product  Financial                      Financial Dimensions (Global)   \n",
       "129  Product  Financial       Comodity Code --> UN Commodity Code (Global)   \n",
       "130  Product  Financial  Country/Region --> Country of Origin/ISO Locat...   \n",
       "\n",
       "                                                     3  \n",
       "0    https://purview.microsoft.com/datacatalog/gove...  \n",
       "1    [Product Platform Document or Description -> h...  \n",
       "2                                                  NaN  \n",
       "3    https://purview.microsoft.com/datacatalog/gove...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "126                                                NaN  \n",
       "127                                                NaN  \n",
       "128                                                NaN  \n",
       "129                                                NaN  \n",
       "130                                                NaN  \n",
       "\n",
       "[131 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_clipboard(header=None)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Object</th>\n",
       "      <th>Data Object Child</th>\n",
       "      <th>Data Object Attribute</th>\n",
       "      <th>Attribute Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SKU Number</td>\n",
       "      <td>https://purview.microsoft.com/datacatalog/gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Description</td>\n",
       "      <td>[Product Platform Document or Description -&gt; h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Part Type</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Group Code</td>\n",
       "      <td>https://purview.microsoft.com/datacatalog/gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Type Code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Item Group (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Item Sales Tax Group (Local)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Financial Dimensions (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Comodity Code --&gt; UN Commodity Code (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Country/Region --&gt; Country of Origin/ISO Locat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Object Data Object Child  \\\n",
       "0       Product               NaN   \n",
       "1       Product               NaN   \n",
       "2       Product               NaN   \n",
       "3       Product               NaN   \n",
       "4       Product               NaN   \n",
       "..          ...               ...   \n",
       "126     Product         Financial   \n",
       "127     Product         Financial   \n",
       "128     Product         Financial   \n",
       "129     Product         Financial   \n",
       "130     Product         Financial   \n",
       "\n",
       "                                 Data Object Attribute  \\\n",
       "0                                           SKU Number   \n",
       "1                                  Product Description   \n",
       "2                                            Part Type   \n",
       "3                                   Product Group Code   \n",
       "4                                    Product Type Code   \n",
       "..                                                 ...   \n",
       "126                                Item Group (Global)   \n",
       "127                       Item Sales Tax Group (Local)   \n",
       "128                      Financial Dimensions (Global)   \n",
       "129       Comodity Code --> UN Commodity Code (Global)   \n",
       "130  Country/Region --> Country of Origin/ISO Locat...   \n",
       "\n",
       "                                 Attribute Description  \n",
       "0    https://purview.microsoft.com/datacatalog/gove...  \n",
       "1    [Product Platform Document or Description -> h...  \n",
       "2                                                  NaN  \n",
       "3    https://purview.microsoft.com/datacatalog/gove...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "126                                                NaN  \n",
       "127                                                NaN  \n",
       "128                                                NaN  \n",
       "129                                                NaN  \n",
       "130                                                NaN  \n",
       "\n",
       "[131 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns = ['Data Object', 'Data Object Child', 'Data Object Attribute', 'Attribute Description']\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities as my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_object</th>\n",
       "      <th>data_object_child</th>\n",
       "      <th>data_object_attribute</th>\n",
       "      <th>attribute_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SKU Number</td>\n",
       "      <td>https://purview.microsoft.com/datacatalog/gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Description</td>\n",
       "      <td>[Product Platform Document or Description -&gt; h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Part Type</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Group Code</td>\n",
       "      <td>https://purview.microsoft.com/datacatalog/gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Type Code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Item Group (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Item Sales Tax Group (Local)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Financial Dimensions (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Comodity Code --&gt; UN Commodity Code (Global)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Product</td>\n",
       "      <td>Financial</td>\n",
       "      <td>Country/Region --&gt; Country of Origin/ISO Locat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_object data_object_child  \\\n",
       "0       Product               NaN   \n",
       "1       Product               NaN   \n",
       "2       Product               NaN   \n",
       "3       Product               NaN   \n",
       "4       Product               NaN   \n",
       "..          ...               ...   \n",
       "126     Product         Financial   \n",
       "127     Product         Financial   \n",
       "128     Product         Financial   \n",
       "129     Product         Financial   \n",
       "130     Product         Financial   \n",
       "\n",
       "                                 data_object_attribute  \\\n",
       "0                                           SKU Number   \n",
       "1                                  Product Description   \n",
       "2                                            Part Type   \n",
       "3                                   Product Group Code   \n",
       "4                                    Product Type Code   \n",
       "..                                                 ...   \n",
       "126                                Item Group (Global)   \n",
       "127                       Item Sales Tax Group (Local)   \n",
       "128                      Financial Dimensions (Global)   \n",
       "129       Comodity Code --> UN Commodity Code (Global)   \n",
       "130  Country/Region --> Country of Origin/ISO Locat...   \n",
       "\n",
       "                                 attribute_description  \n",
       "0    https://purview.microsoft.com/datacatalog/gove...  \n",
       "1    [Product Platform Document or Description -> h...  \n",
       "2                                                  NaN  \n",
       "3    https://purview.microsoft.com/datacatalog/gove...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "126                                                NaN  \n",
       "127                                                NaN  \n",
       "128                                                NaN  \n",
       "129                                                NaN  \n",
       "130                                                NaN  \n",
       "\n",
       "[131 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = my.rename_columns(new_df)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
