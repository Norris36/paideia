{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "What is the objective of this notebook? </br>\n",
    "The objective of this notebook is to create a scipt which can make a repository of recipes and their ingredients. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below i will import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pyperclip as py\n",
    "import openai \n",
    "import os\n",
    "import pandas as pd\n",
    "# from    dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# openai.api_type     = os.getenv('OPENAI_TYPE')\n",
    "# openai.api_base     = os.getenv('OPENAI_BASE')\n",
    "# openai.api_version  = os.getenv('OPENAI_VERSION')\n",
    "# openai.api_key      = os.getenv('OPENAI_KEY')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from tqdm import tqdm\n",
    "\n",
    "import helper as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the recipes data \n",
    "recipes = pd.read_csv('recipes.csv')\n",
    "# Load the ingredients data\n",
    "ingredients = pd.read_csv('ingredients_df.csv')\n",
    "# Load the pantry data\n",
    "pantry = pd.read_csv('pantry.csv')\n",
    "# Load the conversion data\n",
    "conversion = pd.read_csv('conversion.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_on_same_domain(url, max_urls=1000):\n",
    "    \"\"\"\n",
    "    Counts the number of unique URLs on the same domain as the given URL,\n",
    "    iterating through links until no more are found or a max limit is reached.\n",
    "    The progress is displayed using tqdm.\n",
    "\n",
    "    Args:\n",
    "    url (str): The starting URL to fetch and analyze.\n",
    "    max_urls (int): Maximum number of URLs to fetch.\n",
    "\n",
    "    Returns:\n",
    "    int: The total number of unique URLs found on the same domain.\n",
    "    \"\"\"\n",
    "    visited_urls = set()\n",
    "    urls_to_visit = set([url])\n",
    "    domain = urlparse(url).netloc\n",
    "\n",
    "    with tqdm(total=max_urls, desc=f\"Analyzing URLs currently found {len(visited_urls)}, and have {len(urls_to_visit)} to go\", unit=\"url\") as pbar:\n",
    "        while len(urls_to_visit) != 0 and len(urls_to_visit) < max_urls:\n",
    "            current_url = urls_to_visit.pop()\n",
    "            try:\n",
    "                response = requests.get(current_url)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                anchors = soup.find_all('a', href=True)\n",
    "\n",
    "                for anchor in anchors:\n",
    "                    href = anchor['href']\n",
    "                    full_url = urljoin(current_url, href)\n",
    "                    href_domain = urlparse(full_url).netloc\n",
    "\n",
    "                    if href_domain == domain and full_url not in visited_urls and '#comment' not in full_url and '#respond' not in full_url:\n",
    "                        urls_to_visit.add(full_url)\n",
    "\n",
    "                visited_urls.add(current_url)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f\"Analyzing URLs currently found {len(visited_urls)}, and have {len(urls_to_visit)} to go\")\n",
    "            except requests.RequestException:\n",
    "                # Handle exceptions for requests\n",
    "                continue\n",
    "\n",
    "    return visited_urls, urls_to_visit\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    \"\"\"\n",
    "    Fetches the content from a given URL and returns the text separated by lines.\n",
    "    If the URL gets redirected more than twice, returns 'redirect link'.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL from which to fetch the content.\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing the text from the URL, separated by lines, or 'redirect link'.\n",
    "    \"\"\"\n",
    "    # Send a GET request to the URL with redirection allowed\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    \n",
    "    # Check the number of redirects\n",
    "    if len(response.history) > 2:\n",
    "        return 'redirect link'\n",
    "    \n",
    "    # Raise an exception if the request was unsuccessful\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract and return the text, separated by lines\n",
    "    return '\\n'.join(soup.stripped_strings)\n",
    "\n",
    "def ingredients_cleaner(text):\n",
    "    try:\n",
    "        text = text.split('Ingredienser')[1]\n",
    "        text = text.split('Udskriv')[0]\n",
    "        text = text.strip()\n",
    "    except:\n",
    "        text = ''\n",
    "    if 'Archive' in text:\n",
    "        text = ''\n",
    "    return text\n",
    "\n",
    "def set_individual_price(row):\n",
    "    amount = row['amounts']\n",
    "    purchase_size = row['purchase_size']\n",
    "    price = row['price']\n",
    "    input_units = row['units']\n",
    "    purchase_unit = row['purchase_unit']\n",
    "    if len(conversion[(conversion.units == input_units) & (conversion.purchase_unit == purchase_unit)] ) > 0:\n",
    "        faktor = conversion[(conversion.units == input_units) & (conversion.purchase_unit == purchase_unit)].rate.values[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    if purchase_size == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        if input_units == purchase_unit:\n",
    "            y = np.ceil(amount / purchase_size) * price if amount > purchase_size else price\n",
    "        else:\n",
    "            if input_units == 'g' and purchase_unit == 'stk':\n",
    "                y = price\n",
    "            else:\n",
    "                # we need to make it so that it looks in the conversion table and then returns the \n",
    "                y = np.ceil(amount * faktor / purchase_size) * price  if amount > purchase_size else price\n",
    "    \n",
    "    # lets also round the product of faktor by purchase_size and amount\n",
    "    z = np.ceil(amount / purchase_size) * faktor if amount > purchase_size else faktor * amount\n",
    "    \n",
    "    return y\n",
    "\n",
    "def find_dinner(test_text, test_url):\n",
    "    segment = test_text.split(test_url)[1]\n",
    "    if 'Aftensmad' in segment:\n",
    "        if 'Tilbehør Aftensmad' in segment:\n",
    "            return False\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_vegeterian(test_text, test_url):\n",
    "    segment = test_text.split(test_url)[1]\n",
    "    if 'Vegetar' in segment:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_addon(test_text, test_url):\n",
    "    segment = test_text.split(test_url)[1]\n",
    "    if 'Tilbehør Aftensmad' in segment:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ing_extract_measurement(line, measurements):\n",
    "    \"\"\"This function extracts the measurement from a line of text, from the ingredients_df\n",
    "\n",
    "    Args:\n",
    "        line (str): ingredients line\n",
    "        measurements (list): list of measurements\n",
    "\n",
    "    Returns:\n",
    "        str: measurement\n",
    "    \"\"\"\n",
    "    local_measurement = ''\n",
    "\n",
    "    for measurement in measurements:\n",
    "        if f'{measurement} ' in line:\n",
    "            return measurement\n",
    "        \n",
    "    return local_measurement\n",
    "\n",
    "def implied_terms(ingredient):\n",
    "    if 'øko' in ingredient:\n",
    "        ingredient = ingredient.replace('øko', '')\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def extract_measurement(line, measurements):\n",
    "    local_measurement = ''\n",
    "\n",
    "    for measurement in measurements:\n",
    "        if f' {measurement} ' in line:\n",
    "            return measurement\n",
    "        \n",
    "    return local_measurement\n",
    "\n",
    "def extract_amount(line):\n",
    "    pattern = '^\\d+'\n",
    "    match = re.findall(pattern, line)\n",
    "    if len(match) > 0:\n",
    "        return match[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def extract_ingredient(line, measurement):\n",
    "    \"\"\"This function extracts the ingredient from a line of text\n",
    "\n",
    "    Args:\n",
    "        line (str): a line of text containg an ingredient, amount and measurement\n",
    "        measurement (list): a list of measurements\n",
    "\n",
    "    Returns:\n",
    "        amount: the amount of the ingredient\n",
    "        measurement: the measurement of the ingredient\n",
    "        new_line: the ingredient\n",
    "    \"\"\"\n",
    "    amount = extract_amount(line)\n",
    "    local_measurement = extract_measurement(line, measurement)\n",
    "    if local_measurement != '':\n",
    "        new_line = line.replace(amount, '')\n",
    "        new_line = new_line.replace(f' {local_measurement} ', '')\n",
    "        new_line = new_line.strip()\n",
    "    else:\n",
    "        new_line = line.replace(amount, '')\n",
    "        new_line = new_line.strip()\n",
    "\n",
    "    # now lets clean up after the measurement\n",
    "    if ',' in amount:\n",
    "        amount = amount.replace(',', '.')\n",
    "        new_line = new_line.replace(amount, '')\n",
    "        new_line = new_line.strip()\n",
    "    else:\n",
    "        new_line = new_line.replace(amount, '')\n",
    "        new_line = new_line.strip()\n",
    "\n",
    "    # now lets remove the implied terms\n",
    "    new_line = implied_terms(new_line)\n",
    "    new_line = new_line.strip()\n",
    "\n",
    "    return amount, local_measurement, new_line\n",
    "\n",
    "def ingredients_setter(ingredients_text, url, measurements, pantry):\n",
    "    \"\"\"This function takes a string of ingredients and sets them in the pantry\"\"\"\n",
    "    ingredients_text = ingredients_cleaner(ingredients_text)    \n",
    "\n",
    "    for line in ingredients_text.splitlines():\n",
    "        amount, local_measurement, new_line = extract_ingredient(line, measurements)\n",
    "        pantry.loc[len(pantry)] = [url, amount, local_measurement, new_line]\n",
    "\n",
    "    return pantry\n",
    "\n",
    "def get_measurements(conversion):\n",
    "    \"\"\"This function returns a list of all the measurements that we have in the conversion table\n",
    "\n",
    "    Args:\n",
    "        conversion (DataFrame): the conversion dataframe \n",
    "\n",
    "    Returns:\n",
    "        list: a list of all the measurements that we have in the conversion table\n",
    "    \"\"\"\n",
    "    # weird measurements\n",
    "    measurements = ['drys', 'dryp', 'skiver', 'skive', 'stængel', 'stængler', 'ark', 'dåser', 'dåse', 'pakke', 'pakker', 'håndfulde', 'håndfuld']\n",
    "\n",
    "    # now lets get all the measurements from the conversion table, and add them to the measurements list\n",
    "    for measurement in conversion.units.unique():\n",
    "        measurements.append(measurement)\n",
    "\n",
    "    return measurements\n",
    "\n",
    "measurements = get_measurements(conversion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def urls_on_same_domain(url, max_urls=1000):\n",
    "    \"\"\"\n",
    "    Counts the number of unique URLs on the same domain as the given URL,\n",
    "    iterating through links until no more are found or a max limit is reached.\n",
    "    The progress is displayed using tqdm.\n",
    "\n",
    "    Args:\n",
    "    url (str): The starting URL to fetch and analyze.\n",
    "    max_urls (int): Maximum number of URLs to fetch.\n",
    "\n",
    "    Returns:\n",
    "    int: The total number of unique URLs found on the same domain.\n",
    "    \"\"\"\n",
    "    visited_urls = set()\n",
    "    urls_to_visit = set([url])\n",
    "    domain = urlparse(url).netloc\n",
    "\n",
    "    # Common user-agent string of a web browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    with tqdm(total=max_urls, desc=f\"Analyzing URLs currently found {len(visited_urls)}, and have {len(urls_to_visit)} to go\", unit=\"url\") as pbar:\n",
    "        while len(urls_to_visit) != 0 and len(visited_urls) < max_urls:\n",
    "            current_url = urls_to_visit.pop()\n",
    "            try:\n",
    "                response = requests.get(current_url, headers=headers)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                anchors = soup.find_all('a', href=True)\n",
    "\n",
    "                for anchor in anchors:\n",
    "                    href = anchor['href']\n",
    "                    full_url = urljoin(current_url, href)\n",
    "                    href_domain = urlparse(full_url).netloc\n",
    "\n",
    "                    if href_domain == domain and full_url not in visited_urls and '#comment' not in full_url and '#respond' not in full_url:\n",
    "                        urls_to_visit.add(full_url)\n",
    "\n",
    "                visited_urls.add(current_url)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f\"Analyzing URLs currently found {len(visited_urls)}, and have {len(urls_to_visit)} to go\")\n",
    "            except requests.RequestException:\n",
    "                # Handle exceptions for requests\n",
    "                continue\n",
    "\n",
    "    return len(visited_urls)\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    \"\"\"\n",
    "    Fetches the content from a given URL and returns the text separated by lines.\n",
    "    If the URL gets redirected more than twice, returns 'redirect link'.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL from which to fetch the content.\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing the text from the URL, separated by lines, or 'redirect link'.\n",
    "    \"\"\"\n",
    "    # Common user-agent string of a web browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the URL with the user-agent header and redirection allowed\n",
    "    response = requests.get(url, headers=headers, allow_redirects=True)\n",
    "    \n",
    "    # Check the number of redirects\n",
    "    if len(response.history) > 2:\n",
    "        return 'redirect link'\n",
    "    \n",
    "    # Raise an exception if the request was unsuccessful\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract and return the text, separated by lines\n",
    "    return '\\n'.join(soup.stripped_strings)\n",
    "\n",
    "url = 'https://vegetariskhverdag.dk/opskrifter/'\n",
    "\n",
    "#test = get_text_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "håndfulde baby spinat baby spinat håndfulde\n",
      "håndfulde isterninger isterninger håndfulde\n"
     ]
    }
   ],
   "source": [
    "def get_measurements(conversion):\n",
    "    \"\"\"This function returns a list of all the measurements that we have in the conversion table\n",
    "\n",
    "    Args:\n",
    "        conversion (DataFrame): the conversion dataframe \n",
    "\n",
    "    Returns:\n",
    "        list: a list of all the measurements that we have in the conversion table\n",
    "    \"\"\"\n",
    "    # weird measurements\n",
    "    measurements = ['drys', 'dryp', 'skiver', 'skive', 'stængel', 'stængler', 'ark', 'dåser', 'dåse', 'pakke', 'pakker', 'håndfulde', 'håndfuld']\n",
    "\n",
    "    # now lets get all the measurements from the conversion table, and add them to the measurements list\n",
    "    for measurement in conversion.units.unique():\n",
    "        measurements.append(measurement)\n",
    "\n",
    "    return measurements\n",
    "\n",
    "measurements = get_measurements(conversion)\n",
    "\n",
    "get_measurements(conversion)\n",
    "\n",
    "removeable = ['drys', 'dryp', 'skiver', 'skive', 'stængel', 'stængler', 'ark', 'dåser', 'dåse', 'pakke', 'pakker', 'håndfulde', 'bakke', 'bakker']\n",
    "# removeable = ['håndfulde', 'håndfuld']\n",
    "\n",
    "for ingredient in ingredients.ingredients.unique():\n",
    "    local_measurement = ing_extract_measurement(ingredient, measurements)\n",
    "    new_ingredient = ''\n",
    "    if local_measurement in removeable:\n",
    "        new_ingredient = ingredient.replace(f'{local_measurement} ', '')\n",
    "        new_ingredient = new_ingredient.strip()\n",
    "\n",
    "        if new_ingredient != '':\n",
    "            print(ingredient, new_ingredient, local_measurement)\n",
    "            ingredients.loc[ingredients.ingredients == ingredient, 'ingredients'] = new_ingredient\n",
    "            # now lets make sure that we set the unit to grams\n",
    "            # pantry.loc[pantry.ingredients == ingredient, 'units'] = 'g'\n",
    "            # now lets multiply the amount by 25 grams\n",
    "            # pantry.loc[pantry.ingredients == ingredient, 'amounts'] = pantry.loc[pantry.ingredients == new_ingredient, 'amounts'] * 25\n",
    "            pantry.loc[pantry.ingredients == ingredient, 'ingredients'] = new_ingredient\n",
    "\n",
    "        else:\n",
    "            print('error',ingredient)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [04:52<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "text = open('dovne_vegetar.txt', 'r').read()\n",
    "text = text.splitlines()\n",
    "# now lets remove any item which contains 'reply-title'\n",
    "text = [item for item in text if 'reply-title' not in item]\n",
    "text = [item for item in text if '/vare/' not in item]\n",
    "text = [item for item in text if '/wp-content/' not in item]\n",
    "\n",
    "df = pd.DataFrame(text, columns=['url'])\n",
    "df['text']  = ''\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    df.loc[index, 'text'] = get_text_from_url(row['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets test if the texts contain '\\nIngredienser\\n'\n",
    "df['has_ingredienser'] = df.text.apply(lambda x: True if '\\nIngredienser\\n' in x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.has_ingredienser == True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 dl røde ris (eller andre ris)\\n1 god håndfuld cashewnødder\\nGrøntsager efter eget valg (her: 1 rødløg, 2 røde snackpeber & 1/2 spidskålshoved)\\n1 spsk revet ingefær\\n1-2 fed hvidløg, fintrevet\\n3 spsk grøntsagsfond (eller vand + et nip salt)\\n2 tsk majsstivelse (maizena)\\n2 spsk soja\\n1 spsk lys sirup (eller honning/sukker/agave)\\n2 spsk riseddike eller anden lys eddike\\n1-1,5 spsk ristet sesamolie\\n1-2 tsk chili flakes\\nSådan gør du\\nSæt risene over efter instruktionerne på pakken.\\nRist cashewnødderne gyldne.\\nSkær grøntsagerne ud i passende stykker. Jeg skar løget i skiver og de andre grøntsager i grove stykker. Riv ingefær og hvidløg fint.\\nBland fond/vand (kold) og maizena sammen i en skål. Tilsæt soja, sirup, eddike og sesamolie.\\nSteg grøntsagerne ved høj varme, så de får godt med farve. Du kan evt stege dem i omgange. Tilsæt ingefær og hvidløg til sidst, så det ikke brænder på. Steg i 1-2 minutter og hæld så din sovs over. Lad simre i 1 minut og smag til med evt mere soja/sirup/eddike/sesamolie. Server med ris og cashewnødderne på toppen!\\nDu kan også tilsætte stegt tofu, æg eller edamamebønner for endnu mere mæthed.\\n14\\n⬅︎ Tryk på hjertet, hvis du kan lide indlægget\\nLoading...\\nSkriv en kommentar\\nFølg Vegetarisk Hverdag på\\nInstagram\\n,\\nFacebook\\neller\\nBloglovin’\\nfor opdateringer om nye opskrifter.\\nHvis du kan lide denne, så prøv også:\\nThailandsk æggesalat\\nVeganske stegte nudler á la Pad Thai\\nIndlægsnavigation\\nPirogger med feta & grønkål\\nHjemmelavet japansk blommevin (umeshu)\\nSkriv en kommentar\\nAnnuller svar\\nDin e-mailadresse vil ikke blive publiceret.\\nKrævede felter er markeret med\\n*\\nNavn\\n*\\nEmail adresse\\n*\\nWebsite\\nKommentér\\nGem mit navn, email og hjemmeside i denne browser til næste gang\\nΔ\\nSkriv dig op til mit nyhedsbrev\\n*\\nobligatorisk\\nEmail\\n*\\nFornavn\\nVegetarisk Hverdag\\nVegetarisk Hverdag er en vegetarisk blog startet i efteråret 2018 af Camilla Skov. Her finder du hverdagsvenlige vegetariske opskrifter og inspiration til vegetarisk aftensmad med fokus på madglæde og velsmag.\\nAlt indhold på sitet © Camilla Skov\\nCVR: 38627457\\nOm & Kontakt\\nOm\\nKontakt\\nSamarbejder\\nForedrag\\nCopyright\\nCookies & Persondata\\nFølg med her\\nInstagram\\nFacebook\\nNyhedsbrev\\nShop\\nWebshop\\nHandelsbetingelser\\nKundeservice\\nElara\\nby LyraThemes\\nMade by\\nLyraThemes.com\\nHjemmesiden bruger cookies for at gøre din oplevelse bedre. Hvis det ikke er ok for dig, kan du vælge cookies fra.\\nCookie settings\\nTillad\\nPrivacy & Cookies Policy\\nLuk\\nPrivacy Overview\\nThis website uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.\\nNecessary\\nNecessary\\nAltid aktiveret\\nNecessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information.\\nNon-necessary\\nNon-necessary\\nAny cookies that may not be particularly necessary for the website to function and is used specifically to collect user personal data via analytics, ads, other embedded contents are termed as non-necessary cookies. It is mandatory to procure user consent prior to running these cookies on your website.\\nGEM & ACCEPTÈR\\nBlack weekend tilbud! Køb Billig mad på dyre tallerkener med 30 % rabat til og med på søndag. <3\\nLuk\\nSearch for:\\nSearch Button'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.text.sample(1).values[0]\n",
    "sample = sample.split('\\nIngredienser')[1]\n",
    "sample = sample.split('portioner\\n')[1]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dl røde ris (eller andre ris)\n",
      "1 håndfuld godcashewnødder\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m measurements \u001b[38;5;241m=\u001b[39m get_measurements(conversion)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39msplitlines():\n\u001b[0;32m---> 86\u001b[0m     amount, local_measurement, new_line \u001b[38;5;241m=\u001b[39m \u001b[43mextract_ingredient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(amount, local_measurement, new_line)\n",
      "Cell \u001b[0;32mIn[56], line 37\u001b[0m, in \u001b[0;36mextract_ingredient\u001b[0;34m(line, measurement)\u001b[0m\n\u001b[1;32m     35\u001b[0m     new_line \u001b[38;5;241m=\u001b[39m new_line\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     new_line \u001b[38;5;241m=\u001b[39m \u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     new_line \u001b[38;5;241m=\u001b[39m new_line\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# now lets clean up after the measurement\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not int"
     ]
    }
   ],
   "source": [
    "def extract_measurement(line, measurements):\n",
    "    local_measurement = ''\n",
    "\n",
    "    for measurement in measurements:\n",
    "        if f' {measurement} ' in line:\n",
    "            return measurement\n",
    "        \n",
    "    return local_measurement\n",
    "\n",
    "def extract_amount(line):\n",
    "    pattern = '^\\d+'\n",
    "    match = re.findall(pattern, line)\n",
    "    if len(match) > 0:\n",
    "        return match[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def extract_ingredient(line, measurement):\n",
    "    \"\"\"This function extracts the ingredient from a line of text\n",
    "\n",
    "    Args:\n",
    "        line (str): a line of text containg an ingredient, amount and measurement\n",
    "        measurement (list): a list of measurements\n",
    "\n",
    "    Returns:\n",
    "        amount: the amount of the ingredient\n",
    "        measurement: the measurement of the ingredient\n",
    "        new_line: the ingredient\n",
    "    \"\"\"\n",
    "    amount = extract_amount(line)\n",
    "    local_measurement = extract_measurement(line, measurement)\n",
    "    if local_measurement != '':\n",
    "        new_line = line.replace(amount, '')\n",
    "        new_line = new_line.replace(f' {local_measurement} ', '')\n",
    "        new_line = new_line.strip()\n",
    "    else:\n",
    "        new_line = line.replace(amount, '')\n",
    "        new_line = new_line.strip()\n",
    "\n",
    "    # now lets clean up after the measurement\n",
    "    if ',' in amount:\n",
    "        amount = amount.replace(',', '.')\n",
    "        new_line = new_line.replace(amount, '')\n",
    "        new_line = new_line.strip()\n",
    "    else:\n",
    "        new_line = new_line.replace(amount, '')\n",
    "        new_line = new_line.strip()\n",
    "\n",
    "    # now lets remove the implied terms\n",
    "    new_line = implied_terms(new_line)\n",
    "    new_line = new_line.strip()\n",
    "\n",
    "    return amount, local_measurement, new_line\n",
    "\n",
    "def ingredients_setter(ingredients_text, url, measurements, pantry):\n",
    "    \"\"\"This function takes a string of ingredients and sets them in the pantry\"\"\"\n",
    "    ingredients_text = ingredients_cleaner(ingredients_text)    \n",
    "\n",
    "    for line in ingredients_text.splitlines():\n",
    "        amount, local_measurement, new_line = extract_ingredient(line, measurements)\n",
    "        pantry.loc[len(pantry)] = [url, amount, local_measurement, new_line]\n",
    "\n",
    "    return pantry\n",
    "\n",
    "def get_measurements(conversion):\n",
    "    \"\"\"This function returns a list of all the measurements that we have in the conversion table\n",
    "\n",
    "    Args:\n",
    "        conversion (DataFrame): the conversion dataframe \n",
    "\n",
    "    Returns:\n",
    "        list: a list of all the measurements that we have in the conversion table\n",
    "    \"\"\"\n",
    "    # weird measurements\n",
    "    measurements = ['drys', 'dryp', 'skiver', 'skive', 'stængel', 'stængler', 'ark', 'dåser', 'dåse', 'pakke', 'pakker', 'håndfulde', 'håndfuld']\n",
    "\n",
    "    # now lets get all the measurements from the conversion table, and add them to the measurements list\n",
    "    for measurement in conversion.units.unique():\n",
    "        measurements.append(measurement)\n",
    "\n",
    "    return measurements\n",
    "\n",
    "measurements = get_measurements(conversion)\n",
    "\n",
    "for line in sample.splitlines():\n",
    "    amount, local_measurement, new_line = extract_ingredient(line, measurements)\n",
    "    print(amount, local_measurement, new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dovne_vegetar.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "04b815c6f433821a83cc9e9c7b49330b771dd14bac87c94a36c7a9e0484b87a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
